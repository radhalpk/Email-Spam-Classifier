{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hanuh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hanuh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import string\n",
    "import nltk ##its used to build python programs that works with human language data for statistical nlp\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "# nltk.download('porter')\n",
    "from nltk import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './EMAIL_spam_dataset/enronSpamSubset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df1\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./EMAIL_spam_dataset/enronSpamSubset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m df1\n",
      "File \u001b[1;32mc:\\Users\\hanuh\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\hanuh\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\hanuh\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\hanuh\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\hanuh\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './EMAIL_spam_dataset/enronSpamSubset.csv'"
     ]
    }
   ],
   "source": [
    "df1=pd.read_csv(\"./EMAIL_spam_dataset/enronSpamSubset.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns={\"Unnamed: 0.1\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2469</td>\n",
       "      <td>Subject: stock promo mover : cwtd\\n * * * urge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5063</td>\n",
       "      <td>Subject: are you listed in major search engine...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12564</td>\n",
       "      <td>Subject: important information thu , 30 jun 20...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2796</td>\n",
       "      <td>Subject: = ? utf - 8 ? q ? bask your life with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1468</td>\n",
       "      <td>Subject: \" bidstogo \" is places to go , things...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>26222</td>\n",
       "      <td>Subject: monday 22 nd oct\\n louise ,\\n do you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>18630</td>\n",
       "      <td>Subject: missing bloomberg deals\\n stephanie -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>18451</td>\n",
       "      <td>Subject: eops salary survey questionnaire\\n we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>21955</td>\n",
       "      <td>Subject: q 3 comparison\\n hi louise ,\\n i have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>32062</td>\n",
       "      <td>Subject: confidential folder to safely pass in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Body  Label\n",
       "0           2469  Subject: stock promo mover : cwtd\\n * * * urge...      1\n",
       "1           5063  Subject: are you listed in major search engine...      1\n",
       "2          12564  Subject: important information thu , 30 jun 20...      1\n",
       "3           2796  Subject: = ? utf - 8 ? q ? bask your life with...      1\n",
       "4           1468  Subject: \" bidstogo \" is places to go , things...      1\n",
       "...          ...                                                ...    ...\n",
       "9995       26222  Subject: monday 22 nd oct\\n louise ,\\n do you ...      0\n",
       "9996       18630  Subject: missing bloomberg deals\\n stephanie -...      0\n",
       "9997       18451  Subject: eops salary survey questionnaire\\n we...      0\n",
       "9998       21955  Subject: q 3 comparison\\n hi louise ,\\n i have...      0\n",
       "9999       32062  Subject: confidential folder to safely pass in...      0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: great part-time or summer job !\\n \\n ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: auto insurance rates too high ?\\n \\n ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: do want the best and economical hunti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: email 57 million people for $ 99\\n \\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: do n't miss these !\\n \\n attention ! ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>2600</td>\n",
       "      <td>Subject: computationally - intensive methods i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>2601</td>\n",
       "      <td>Subject: books : a survey of american linguist...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>2602</td>\n",
       "      <td>Subject: wecol ' 98 - - western conference on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>2603</td>\n",
       "      <td>Subject: euralex ' 98 - revised programme\\n \\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>2604</td>\n",
       "      <td>,Body,Label\\n 0,\"Subject: great part-time or s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2605 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Body  Label\n",
       "0              0  Subject: great part-time or summer job !\\n \\n ...      1\n",
       "1              1  Subject: auto insurance rates too high ?\\n \\n ...      1\n",
       "2              2  Subject: do want the best and economical hunti...      1\n",
       "3              3  Subject: email 57 million people for $ 99\\n \\n...      1\n",
       "4              4  Subject: do n't miss these !\\n \\n attention ! ...      1\n",
       "...          ...                                                ...    ...\n",
       "2600        2600  Subject: computationally - intensive methods i...      0\n",
       "2601        2601  Subject: books : a survey of american linguist...      0\n",
       "2602        2602  Subject: wecol ' 98 - - western conference on ...      0\n",
       "2603        2603  Subject: euralex ' 98 - revised programme\\n \\n...      0\n",
       "2604        2604  ,Body,Label\\n 0,\"Subject: great part-time or s...      0\n",
       "\n",
       "[2605 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.read_csv(\"./EMAIL_spam_dataset/lingSpam.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nSave up to 70% on Life Insurance.\\nWhy Spend...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>##############################################...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I thought you might like these:\\n1) Slim Down ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>6041</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>6042</td>\n",
       "      <td>___           ___           ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>6043</td>\n",
       "      <td>IN THIS ISSUE:01. Readers write\\n02. Extension...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>6044</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>6045</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6046 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Body  Label\n",
       "0              0  \\nSave up to 70% on Life Insurance.\\nWhy Spend...      1\n",
       "1              1  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
       "2              2  1) Fight The Risk of Cancer!\\nhttp://www.adcli...      1\n",
       "3              3  ##############################################...      1\n",
       "4              4  I thought you might like these:\\n1) Slim Down ...      1\n",
       "...          ...                                                ...    ...\n",
       "6041        6041                                              empty      0\n",
       "6042        6042                    ___           ___           ...      0\n",
       "6043        6043  IN THIS ISSUE:01. Readers write\\n02. Extension...      0\n",
       "6044        6044                                              empty      0\n",
       "6045        6045                                              empty      0\n",
       "\n",
       "[6046 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.read_csv(\"./EMAIL_spam_dataset/completeSpamAssassin.csv\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined=pd.concat([df1,df2,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2469</td>\n",
       "      <td>Subject: stock promo mover : cwtd\\n * * * urge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5063</td>\n",
       "      <td>Subject: are you listed in major search engine...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12564</td>\n",
       "      <td>Subject: important information thu , 30 jun 20...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2796</td>\n",
       "      <td>Subject: = ? utf - 8 ? q ? bask your life with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1468</td>\n",
       "      <td>Subject: \" bidstogo \" is places to go , things...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>6041</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>6042</td>\n",
       "      <td>___           ___           ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>6043</td>\n",
       "      <td>IN THIS ISSUE:01. Readers write\\n02. Extension...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>6044</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>6045</td>\n",
       "      <td>empty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18651 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Body  Label\n",
       "0           2469  Subject: stock promo mover : cwtd\\n * * * urge...      1\n",
       "1           5063  Subject: are you listed in major search engine...      1\n",
       "2          12564  Subject: important information thu , 30 jun 20...      1\n",
       "3           2796  Subject: = ? utf - 8 ? q ? bask your life with...      1\n",
       "4           1468  Subject: \" bidstogo \" is places to go , things...      1\n",
       "...          ...                                                ...    ...\n",
       "6041        6041                                              empty      0\n",
       "6042        6042                    ___           ___           ...      0\n",
       "6043        6043  IN THIS ISSUE:01. Readers write\\n02. Extension...      0\n",
       "6044        6044                                              empty      0\n",
       "6045        6045                                              empty      0\n",
       "\n",
       "[18651 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[\"Body\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=combined.drop(columns={'Unnamed: 0'})\n",
    "data=data[~(data.Body=='empty')]\n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: stock promo mover : cwtd\\n * * * urge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: are you listed in major search engine...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: important information thu , 30 jun 20...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: = ? utf - 8 ? q ? bask your life with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: \" bidstogo \" is places to go , things...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18112</th>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18113</th>\n",
       "      <td>EFFector       Vol. 15, No. 35       November ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18114</th>\n",
       "      <td>\\nWe have extended our Free seat sale until Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18115</th>\n",
       "      <td>___           ___           ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>IN THIS ISSUE:01. Readers write\\n02. Extension...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Body  Label\n",
       "0      Subject: stock promo mover : cwtd\\n * * * urge...      1\n",
       "1      Subject: are you listed in major search engine...      1\n",
       "2      Subject: important information thu , 30 jun 20...      1\n",
       "3      Subject: = ? utf - 8 ? q ? bask your life with...      1\n",
       "4      Subject: \" bidstogo \" is places to go , things...      1\n",
       "...                                                  ...    ...\n",
       "18112  ----------------------------------------------...      0\n",
       "18113  EFFector       Vol. 15, No. 35       November ...      0\n",
       "18114  \\nWe have extended our Free seat sale until Th...      0\n",
       "18115                    ___           ___           ...      0\n",
       "18116  IN THIS ISSUE:01. Readers write\\n02. Extension...      0\n",
       "\n",
       "[18117 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Subject: stock promo mover : cwtd\\n * * * urgent investor trading alert * * *\\n weekly stock pick - - china world trade corp . ( ticker : cwtd )\\n * * breaking news * *\\n china world trade corp . enters into agreement to acquire\\n majority stake in ceo clubs china limited ( the ceo clubs )\\n tianhe , guangzhou , china - - ( market wire ) - - apr 7 , 2004 - - china world trade corp\\n ( otc bb : cwtd . ob - news ) announced today that it has entered into an agreement to\\n acquired majority stake in ceo clubs china limited ( the ceo clubs ) , a hong\\n kong corporation with authorized chapter to operate under the ceo clubs\\n trademarks in the greater china region , including the prc , hong kong and taiwan .\\n china world trade corp .\\n symbol : cwtd\\n price $ 4 . 80\\n shares out : 16 million\\n market capitalization : $ 19 million\\n significant revenue growth in 2004\\n average pe industry : 30 x\\n rating : strong buy\\n 7 days trading target : $ 6 . 50\\n 30 day trading target : $ 7 . 50\\n cwtd is our play of the month stock pick .\\n here are a few simple reasons why one would own china world trade corp :\\n china world trade corp announced today that it has entered into an agreement\\n to acquired majority stake in ceo clubs china limited ( the ceo clubs ) , a hong\\n kong corporation with authorized chapter to operate under the ceo clubs\\n trademarks in the greater china region , including the prc , hong kong and taiwan .\\n china world trade corp has just gotten 1 . 2 million cash for working capital\\n from a single shareholder ! !\\n has acquired multiple companies in the past few months resulting in huge assets\\n for the company\\n china world trade corp is in the process of being accepted onto the amex\\n china world trade corporation is an official operator of world trade centers\\n in china , in association with the world trade centers association ( wtca ) and\\n offers an enormous variety of services for businesses and industries seeking\\n to do business in china .\\n the company ' s business model consists of three major components - - the world\\n trade center business , value - added services , and strategic investments .\\n china world trade corporation established the first world trade center in the\\n province of guangzhou ( canton ) in the year 2002 and started the commercial operation\\n at the beginning of 2003 . this significant event was covered in detail on cnn\\n asia .\\n with the recent tragic events of 9 - 11 , the name world trade center has instant\\n global recognition , and stands for unity , strength and prosperity throughout\\n the worlds top economy leaders .\\n china world trade corp signs letter of intent to acquire controlling stake\\n of guangdong huahao industries holdings limited\\n cwtd ' s business potential is built upon the opportunity created by the international\\n trade of china .\\n investment outlook\\n - cwtd has a strong management team that includes top local corporate officers ,\\n high ranking senior government officials and senior management from the hong\\n kong world trade center\\n - in the last twenty years , the foreign direct investment into china has increased\\n from 0 . 92 billion usd in 1983 to 52 . 74 billion usd in 2004\\n - cwtd is firmly positioned to vastly expand its marketing and acquisition\\n strategies and capitalize on asia ' s multi - billion dollar emerging market .\\n - cwtd has just made the application to list on the amex ! ! !\\n - china world trade corp signs letter of intent to acquire controlling stake\\n of guangdong huahao industries holdings limited\\n information within this email contains forward looking statements\\n within the meaning of section 27 a of the securities act of 1933 and section\\n 21 b of the securities exchange act of 1934 . any statements that express or involve\\n discussions with respect to predictions , goals , expectations , beliefs , plans ,\\n projections , objectives , assumptions or future events or performance are not\\n statements of historical fact and may be forward looking statements .\\n zhnwz cgwop ntytd vtmtd ryvka rywrbdqxfb cruma\\n jvqon pgcwj egrdg fdotc tyovo kebkb\\n forward looking statements are based on expectations , estimates and projections\\n at the time the statements are made that involve a number of risks and uncertainties\\n which could cause actual results or events to differ materially from those presently\\n anticipated . forward looking statements in this action may be identified through\\n the use of words such as : projects , foresee , expects ,\\n estimates , believes , understands will ,\\n anticipates , or that by statements indicating certain actions may ,\\n could , or might occur . all information provided within\\n this email pertaining to investing , stocks , securities must be understood as\\n information provided and not investment advice . we advise all readers and subscribers\\n to seek advice from a registered professional securities representative before\\n deciding to trade in stocks featured within this email . none of the material\\n within this report shall be construed as any kind of investment advice . gs research\\n and / or its officers and employees have been compensated 50 , 000 open trade shares\\n by a third party for work involved in the preparation and production of this\\n report\\n in compliance with section 17 ( b ) , we disclose the holding of independently\\n purchased shares of the company mentioned prior to the publication of this report . .\\n be aware of an inherent conflict of interest resulting from such holdings due\\n to our intent to profit from the liquidation of these shares . shares may be\\n sold at any time , even after positive statements have been made regarding the\\n above company . short term trading targets are only guesses on our part . keep\\n in mind that when trading small stocks like the company above there is a chance\\n you will lose every penny you invest . furthermore there have been times in the\\n past when the company itself tells lies , gives false information and puts out\\n false news . this email is for entertainment purposes only . this is not investment\\n advice . we suggest you check with an investment professional before investing\\n any stocks or mutual funds .\\n pkmdk evorz gjdhb zcqym qretp hyexrpchju euqlb\\n tszve zitda xyueq xkumc kuhwz haeex\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Subject: stock promo mover : cwtd\\n * * * urgent investor trading alert * * *\\n weekly stock pick - - china world trade corp . ( ticker : cwtd )\\n * * breaking news * *\\n china world trade corp . enters into agreement to acquire\\n majority stake in ceo clubs china limited ( the ceo clubs )\\n tianhe , guangzhou , china - - ( market wire ) - - apr 7 , 2004 - - china world trade corp\\n ( otc bb : cwtd . ob - news ) announced today that it has entered into an agreement to\\n acquired majority stake in ceo clubs china limited ( the ceo clubs ) , a hong\\n kong corporation with authorized chapter to operate under the ceo clubs\\n trademarks in the greater china region , including the prc , hong kong and taiwan .\\n china world trade corp .\\n symbol : cwtd\\n price $ 4 . 80\\n shares out : 16 million\\n market capitalization : $ 19 million\\n significant revenue growth in 2004\\n average pe industry : 30 x\\n rating : strong buy\\n 7 days trading target : $ 6 . 50\\n 30 day trading target : $ 7 . 50\\n cwtd is our play of the month stock pick .\\n here are a few simple reasons why one would own china world trade corp :\\n china world trade corp announced today that it has entered into an agreement\\n to acquired majority stake in ceo clubs china limited ( the ceo clubs ) , a hong\\n kong corporation with authorized chapter to operate under the ceo clubs\\n trademarks in the greater china region , including the prc , hong kong and taiwan .\\n china world trade corp has just gotten 1 . 2 million cash for working capital\\n from a single shareholder ! !\\n has acquired multiple companies in the past few months resulting in huge assets\\n for the company\\n china world trade corp is in the process of being accepted onto the amex\\n china world trade corporation is an official operator of world trade centers\\n in china , in association with the world trade centers association ( wtca ) and\\n offers an enormous variety of services for businesses and industries seeking\\n to do business in china .\\n the company ' s business model consists of three major components - - the world\\n trade center business , value - added services , and strategic investments .\\n china world trade corporation established the first world trade center in the\\n province of guangzhou ( canton ) in the year 2002 and started the commercial operation\\n at the beginning of 2003 . this significant event was covered in detail on cnn\\n asia .\\n with the recent tragic events of 9 - 11 , the name world trade center has instant\\n global recognition , and stands for unity , strength and prosperity throughout\\n the worlds top economy leaders .\\n china world trade corp signs letter of intent to acquire controlling stake\\n of guangdong huahao industries holdings limited\\n cwtd ' s business potential is built upon the opportunity created by the international\\n trade of china .\\n investment outlook\\n - cwtd has a strong management team that includes top local corporate officers ,\\n high ranking senior government officials and senior management from the hong\\n kong world trade center\\n - in the last twenty years , the foreign direct investment into china has increased\\n from 0 . 92 billion usd in 1983 to 52 . 74 billion usd in 2004\\n - cwtd is firmly positioned to vastly expand its marketing and acquisition\\n strategies and capitalize on asia ' s multi - billion dollar emerging market .\\n - cwtd has just made the application to list on the amex ! ! !\\n - china world trade corp signs letter of intent to acquire controlling stake\\n of guangdong huahao industries holdings limited\\n information within this email contains forward looking statements\\n within the meaning of section 27 a of the securities act of 1933 and section\\n 21 b of the securities exchange act of 1934 . any statements that express or involve\\n discussions with respect to predictions , goals , expectations , beliefs , plans ,\\n projections , objectives , assumptions or future events or performance are not\\n statements of historical fact and may be forward looking statements .\\n zhnwz cgwop ntytd vtmtd ryvka rywrbdqxfb cruma\\n jvqon pgcwj egrdg fdotc tyovo kebkb\\n forward looking statements are based on expectations , estimates and projections\\n at the time the statements are made that involve a number of risks and uncertainties\\n which could cause actual results or events to differ materially from those presently\\n anticipated . forward looking statements in this action may be identified through\\n the use of words such as : projects , foresee , expects ,\\n estimates , believes , understands will ,\\n anticipates , or that by statements indicating certain actions may ,\\n could , or might occur . all information provided within\\n this email pertaining to investing , stocks , securities must be understood as\\n information provided and not investment advice . we advise all readers and subscribers\\n to seek advice from a registered professional securities representative before\\n deciding to trade in stocks featured within this email . none of the material\\n within this report shall be construed as any kind of investment advice . gs research\\n and / or its officers and employees have been compensated 50 , 000 open trade shares\\n by a third party for work involved in the preparation and production of this\\n report\\n in compliance with section 17 ( b ) , we disclose the holding of independently\\n purchased shares of the company mentioned prior to the publication of this report . .\\n be aware of an inherent conflict of interest resulting from such holdings due\\n to our intent to profit from the liquidation of these shares . shares may be\\n sold at any time , even after positive statements have been made regarding the\\n above company . short term trading targets are only guesses on our part . keep\\n in mind that when trading small stocks like the company above there is a chance\\n you will lose every penny you invest . furthermore there have been times in the\\n past when the company itself tells lies , gives false information and puts out\\n false news . this email is for entertainment purposes only . this is not investment\\n advice . we suggest you check with an investment professional before investing\\n any stocks or mutual funds .\\n pkmdk evorz gjdhb zcqym qretp hyexrpchju euqlb\\n tszve zitda xyueq xkumc kuhwz haeex\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=data.Body[0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transfer(x,sw,sp):\n",
    "    x=x.lower()\n",
    "    x=nltk.word_tokenize(x)\n",
    "    y=[]\n",
    "    for i in x:\n",
    "        if i not in sw and i not in sp and i.isalnum():\n",
    "            y.append(ps.stem(i))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw=stopwords.words('english')\n",
    "sp=string.punctuation\n",
    "new_col=data.Body.apply(text_transfer,sw=sw, sp=sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [subject, stock, promo, mover, cwtd, urgent, i...\n",
       "1        [subject, list, major, search, engin, submit, ...\n",
       "2        [subject, import, inform, thu, 30, jun, 2005, ...\n",
       "3        [subject, utf, 8, q, bask, life, utf, 8, q, in...\n",
       "4        [subject, bidstogo, place, go, thing, hello, p...\n",
       "                               ...                        \n",
       "18112    [isilo, tm, palm, os, pocket, pc, window, ente...\n",
       "18113    [effector, vol, 15, 35, novemb, 8, 2002, ren, ...\n",
       "18114    [extend, free, seat, sale, thursday, 21st, nov...\n",
       "18115    [insignific, matter, heavili, overemphasis, hu...\n",
       "18116    [reader, write, extens, search, dumb, messag, ...\n",
       "Name: Body, Length: 18117, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['transferred_text']=new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.transferred_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(data.Label.value_counts(),labels=['ham','spam'],autopct='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(data,open('Email_CleanedData.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transferred_text=df.transferred_text.str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transferred_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_frame=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "dummy=cv.fit_transform(dummy_frame['transferred_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "hv = HashingVectorizer(n_features=10000)  # Adjust the number of features as needed\n",
    "hash_x = hv.fit_transform(df['transferred_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_x=hash_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# xtrain,xtest,ytrain,ytest=train_test_split(hash_x,y,test_size=0.2)\n",
    "x_train,x_test,y_train,y_test=train_test_split(hash_x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb=GaussianNB()\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
    "xgb = XGBClassifier(n_estimators=50,random_state=2)\n",
    "\n",
    "# gnb.fit(xtrain,ytrain)\n",
    "# svc\n",
    "# lrc\n",
    "# rfc\n",
    "# etc\n",
    "# gbdt\n",
    "# xgb\n",
    "#####################################33\n",
    "# mnb=MultinomialNB()\n",
    "# mnb.fit(xtrain,ytrain)\n",
    "# bnb=BernoulliNB()\n",
    "# bnb.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knc = KNeighborsClassifier()\n",
    "# mnb = MultinomialNB()\n",
    "# dtc = DecisionTreeClassifier(max_depth=5)\n",
    "# abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
    "# bc = BaggingClassifier(n_estimators=50, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    # 'GNB' : gnb,\n",
    "    'SVC' : svc,\n",
    "                    # 'KN' : knc, \n",
    "                    # 'NB': mnb, \n",
    "                    # 'DT': dtc, \n",
    "    # 'LR': lrc, \n",
    "    # 'RF': rfc, \n",
    "                    # 'AdaBoost': abc, \n",
    "                    # 'BgC': bc, \n",
    "    'ETC': etc,\n",
    "    # 'GBDT':gbdt,\n",
    "    # 'xgb':xgb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf,x_train,y_train,x_test,y_test):\n",
    "    clf.fit(x_train,y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    return accuracy,precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    current_accuracy,current_precision = train_classifier(clf, x_train,y_train,x_test,y_test)\n",
    "    \n",
    "    print(\"For \",name)\n",
    "    print(\"Accuracy - \",current_accuracy)\n",
    "    print(\"Precision - \",current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer(x):\n",
    "    sw=stopwords.words('english')\n",
    "    sp=string.punctuation\n",
    "    x=x.lower()\n",
    "    x=nltk.word_tokenize(x)\n",
    "    y=[]\n",
    "    for i in x:\n",
    "        if i not in sw and i not in sp and i.isalnum():\n",
    "            y.append(ps.stem(i))\n",
    "    y=[\" \".join(y)]\n",
    "    hash_vector = HashingVectorizer(n_features=10000)  # Adjust the number of features as needed\n",
    "\n",
    "    vector = hash_vector.fit_transform(y).toarray()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=transfer(\"Dear all, Greetings from the Centre for Statistics The Centre for Statistics was started in SRM IST in May 2019. It is a unique feature of our institute. UNCOVER STATISTICAL MASTERY WITH US. -- Prof. M. Bagavandas Head, Centre for Statistics SRM Institute of Science and Technology https://www.srmist.edu.in/centre-for-statistics/\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(etc,open(\"model.pkl\",'wb'))\n",
    "pickle.dump(hv,open(\"vectorizer.pkl\",'wb'))\n",
    "pickle.dump(transfer,open(\"transfer_fun.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_fun=pickle.load(open(\"transfer_fun\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_fun(\"Dear all, Greetings from the Centre for Statistics The Centre for Statistics was started in SRM IST in May 2019. It is a unique feature of our institute. UNCOVER STATISTICAL MASTERY WITH US. -- Prof. M. Bagavandas Head, Centre for Statistics SRM Institute of Science and Technology https://www.srmist.edu.in/centre-for-statistics/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
